{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXVgImHps-Qi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Specify the folder path containing the CSV files\n",
        "folder_path = '/content/drive/MyDrive/validation_clean'\n",
        "\n",
        "# Initialize an empty list to store DataFrames\n",
        "dfs = []\n",
        "\n",
        "# Loop through each file in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith('.csv'):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "\n",
        "        # Read the CSV file into a DataFrame\n",
        "        df = pd.read_csv(file_path)\n",
        "        for feature in ['access_success_rate', 'data_rate', 'resource_utilition_rate', 'TA', 'mcs', 'bler', 'cqi']:\n",
        "            for i in range(1, 2):\n",
        "                df[feature] = df[feature].shift(i)\n",
        "\n",
        "        # Add a new column with the filename as a feature\n",
        "        df['file_name'] = filename\n",
        "\n",
        "        # Append the modified DataFrame to the list\n",
        "        dfs.append(df)\n",
        "\n",
        "# Concatenate all DataFrames into a single DataFrame\n",
        "result_df999 = pd.concat(dfs, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ft4hIU5nltE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Specify the folder path containing the CSV files\n",
        "folder_path = '/content/drive/MyDrive/train_test_dataset_Fault Impact Analysis'\n",
        "\n",
        "# Initialize an empty list to store DataFrames\n",
        "dfs = []\n",
        "\n",
        "# Loop through each file in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith('.csv'):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "\n",
        "        # Read the CSV file into a DataFrame\n",
        "        df = pd.read_csv(file_path)\n",
        "\n",
        "        # Perform operations on the DataFrame\n",
        "        df['data_rate_change'] = df['data_rate'] - df['data_rate'].shift(1)\n",
        "        df['data_rate_change'] = df['data_rate_change'].apply(lambda x: 0 if x > 0 else 1)\n",
        "        for feature in ['access_success_rate', 'data_rate', 'resource_utilition_rate', 'TA', 'mcs', 'bler', 'cqi']:\n",
        "            for i in range(1, 2):\n",
        "                df[feature] = df[feature].shift(i)\n",
        "        index = df[df['fault_duration'] > 0].index[0]\n",
        "        rows_before = df.iloc[:index]\n",
        "        target_row = df.iloc[index]\n",
        "        result = pd.concat([rows_before, target_row], ignore_index=True)\n",
        "        dfs.append(df)\n",
        "\n",
        "# Concatenate all DataFrames into a single DataFrame\n",
        "result_df = pd.concat(dfs, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXzGkvv8sfgt"
      },
      "outputs": [],
      "source": [
        "result_df9=result_df999[result_df999['fault_duration']>0]\n",
        "#result_df99=result_df[result_df['fault_duration']>0]\n",
        "#result_df9.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8xtgl3bKw5P"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "#from catboost import CatBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import KFold,StratifiedKFold ,GroupKFold\n",
        "from sklearn.metrics import mean_absolute_error,f1_score,mean_squared_error,roc_auc_score\n",
        "import lightgbm as lgb\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "import warnings\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn import preprocessing\n",
        "warnings.filterwarnings('ignore')\n",
        "from xgboost import XGBClassifier\n",
        "import tqdm\n",
        "from tqdm import tqdm_notebook\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "train=result_df#pd.read_csv('tttt.csv')\n",
        "train['data_rate_change'].fillna(0,inplace=True)\n",
        "test=result_df9\n",
        "train['win']=1\n",
        "test['win']=0\n",
        "data=pd.concat([train,test]).reset_index(drop=True)\n",
        "data.fillna(df.groupby(['NE ID','endTime'], as_index=False).mean(), inplace=True)\n",
        "data.fillna(df.mean(), inplace=True)\n",
        "data[\"time\"] = pd.to_datetime(data[\"endTime\"])\n",
        "data[\"month\"] = data.time.dt.month\n",
        "data[\"year\"] =  data.time.dt.year\n",
        "data[\"day\"] = data.time.dt.day\n",
        "data[\"hour\"] = data.time.dt.hour\n",
        "data['week']=data.time.dt.weekofyear\n",
        "data['dayofyear']=data.time.dt.dayofyear\n",
        "data['dayofweek']=data.time.dt.dayofweek\n",
        "data[\"is_month_end\"] = data.time.dt.is_month_end\n",
        "data[\"is_quarter_end\"] = data.time.dt.is_quarter_end\n",
        "data[\"is_year_end\"] = data.time.dt.is_year_end\n",
        "data['hour_sin'] = np.sin(2 * np.pi * data['hour'] / 24)\n",
        "data['hour_cos'] = np.cos(2 * np.pi * data['hour'] / 24)\n",
        "data['day_sin'] = np.sin(2 * np.pi * data['dayofweek'] / 7)\n",
        "data['day_cos'] = np.cos(2 * np.pi * data['dayofweek'] / 7)\n",
        "data['mont_sin'] = np.sin(2 * np.pi * data['month'] / 12)\n",
        "data['mont_cos'] = np.cos(2 * np.pi * data['month'] / 12)\n",
        "###\n",
        "engFeature=[ 'fault_duration', 'relation']\n",
        "\n",
        "\n",
        "\n",
        "train=data[data['win']==1]\n",
        "test=data[data['win']==0]\n",
        "feature=[c for c in train.columns if c not in ['kfold','time','0','ID','endTime','NE ID','data_rate_t+1_trend','data_rate_change','file_name','Unnamed: 0']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQLKUcmXKw-E",
        "outputId": "710c4e69-4759-4cb6-ebee-4adf05c2f844"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 379543, number of negative: 347594\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.180049 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2346\n",
            "[LightGBM] [Info] Number of data points in the train set: 727137, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.521969 -> initscore=0.087933\n",
            "[LightGBM] [Info] Start training from score 0.087933\n",
            "fold 0 result == 0.7233184211220194\n",
            "[LightGBM] [Info] Number of positive: 379181, number of negative: 347956\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.125253 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2347\n",
            "[LightGBM] [Info] Number of data points in the train set: 727137, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.521471 -> initscore=0.085938\n",
            "[LightGBM] [Info] Start training from score 0.085938\n",
            "fold 1 result == 0.7251974030531672\n",
            "[LightGBM] [Info] Number of positive: 379152, number of negative: 347986\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073323 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2357\n",
            "[LightGBM] [Info] Number of data points in the train set: 727138, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.521431 -> initscore=0.085775\n",
            "[LightGBM] [Info] Start training from score 0.085775\n",
            "fold 2 result == 0.7245848343730779\n",
            "[LightGBM] [Info] Number of positive: 379496, number of negative: 347642\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074139 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2354\n",
            "[LightGBM] [Info] Number of data points in the train set: 727138, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.521904 -> initscore=0.087671\n",
            "[LightGBM] [Info] Start training from score 0.087671\n",
            "fold 3 result == 0.7243255607314252\n",
            "[LightGBM] [Info] Number of positive: 379332, number of negative: 347806\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.115702 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2350\n",
            "[LightGBM] [Info] Number of data points in the train set: 727138, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.521678 -> initscore=0.086767\n",
            "[LightGBM] [Info] Start training from score 0.086767\n",
            "fold 4 result == 0.7248214655009305\n",
            "0.7244495369561241 0.0006341503082133756\n"
          ]
        }
      ],
      "source": [
        "df=train\n",
        "df['kfold']=-1\n",
        "df=df.sample(frac=1,random_state=1998).reset_index(drop=True)#6,7,11\n",
        "kf=KFold(n_splits=5)\n",
        "for fold,(trn_,val_) in enumerate(kf.split(X=df)):\n",
        "    df.loc[val_,'kfold']=fold\n",
        "df=df\n",
        "from sklearn.linear_model import LinearRegression\n",
        "final_predictions=[]\n",
        "scores=[]#1\n",
        "for fold in range(5):\n",
        "    xtrain=df[df.kfold != fold].reset_index(drop=True)\n",
        "    xvalid=df[df.kfold == fold].reset_index(drop=True)\n",
        "    xtest=test[feature]\n",
        "    ytrain=xtrain.data_rate_change\n",
        "    yvalid=xvalid.data_rate_change\n",
        "    xtrain=xtrain[feature]\n",
        "    xvalid=xvalid[feature]\n",
        "    model=LGBMClassifier(scale_pos_weight=1.5,n_estimators=500,learning_rate=0.05)#n_estimators=4000,learning_rate=0.01)\n",
        "    model.fit(xtrain,ytrain)#early_stopping_rounds=150,eval_set=[(xvalid,yvalid)],verbose=500)\n",
        "    preds_valid=model.predict(xvalid)\n",
        "    predictions=model.predict(xtest)\n",
        "    final_predictions.append(predictions)\n",
        "    rmse=f1_score(yvalid,preds_valid)\n",
        "    print((f'fold {fold} result =='),rmse)\n",
        "    scores.append(rmse)\n",
        "print(np.mean(scores),np.std(scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s05MtG1qKxDZ"
      },
      "outputs": [],
      "source": [
        "test['data_rate_change']=np.mean(np.column_stack(final_predictions),axis=1)#model.predict(test[feature])#\n",
        "test['ID']=test['file_name'].apply(lambda x:x.split('.')[0])\n",
        "test['data_rate_change'] = [1 if x >= 0.61 else 0 for x in test['data_rate_change']]\n",
        "test[['ID','data_rate_change']].to_csv('fault_winn1.csv',index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}